{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This module aims to classify defects observed on glass surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def_device = 'cpu'\n",
    "\n",
    "device = torch.device(def_device)\n",
    "\n",
    "\n",
    "path = Path(\"/Users/kit/Resource/Data/defect/AGDD/data/image/\")\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = get_image_files(path)\n",
    "def img2label(x): \n",
    "    name = Path(x.name).stem\n",
    "\n",
    "    return x.parents[2]/'labels_rect'/Path(x).parent.name/f\"{name}.txt\"\n",
    "img2label(img_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180a2ec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "im = PILImage.create(img_files[0])\n",
    "print(f'image shape: {im.shape}')\n",
    "im.to_thumb(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca191b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torchvision.transforms as T\n",
    "\n",
    "ident = {\n",
    "        0: \"contusion\",\n",
    "        1: \"scratch\",\n",
    "        2: \"crack\",\n",
    "        3: \"spot\",\n",
    "}\n",
    "def box_xyxy_to_cxcywh(x):\n",
    "    x0, y0, x1, y1 = x.unbind(-1)\n",
    "    b = [(x0 + x1) / 2, (y0 + y1) / 2,\n",
    "         (x1 - x0), (y1 - y0)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(-1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=-1)\n",
    "\n",
    "def get_x(x):\n",
    "    image = PILImage.create(x)\n",
    "    tensor = T.ToTensor()(image)\n",
    "    tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "# Convert from (centre_x, centre_y, width, height) to\n",
    "# (upper_left_y, upper_left_x, lower_right_y, lower_right_x)\n",
    "def get_bounding_box(f):\n",
    "    bb = np.genfromtxt(img2label(f))\n",
    "\n",
    "    if bb.ndim == 0:\n",
    "        return None\n",
    "    elif bb.ndim == 1:\n",
    "        bb = np.expand_dims(bb, axis=0)\n",
    "\n",
    "    bb = bb[:, 1:]\n",
    "\n",
    "    for ii in range(bb.shape[0]):\n",
    "        bb[ii] = box_cxcywh_to_xyxy(tensor(bb[ii]))\n",
    "\n",
    "    im_width, im_height = PIL.Image.open(f).size\n",
    "\n",
    "\n",
    "    bb[:, 0] *= im_width\n",
    "    bb[:, 2] *= im_width\n",
    "    bb[:, 1] *= im_height\n",
    "    bb[:, 3] *= im_height\n",
    "\n",
    "    return tensor(bb.astype(int), device=device)\n",
    "\n",
    "def get_label(f):\n",
    "    label = np.genfromtxt(img2label(f))\n",
    "\n",
    "    if label.ndim == 0:\n",
    "        return None\n",
    "    elif label.ndim == 1:\n",
    "        return [ident[label[0]]]\n",
    "    # return tensor([c1, c2])\n",
    "    # Scale centers on [-1, +1]\n",
    "\n",
    "    return [ident[each] for each in label[:, 0]]\n",
    "\n",
    "get_y = [get_bounding_box, get_label]\n",
    "\n",
    "for ii in range(2):\n",
    "    print(ii)\n",
    "    print(get_bounding_box(img_files[ii]))\n",
    "    print(get_label(img_files[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "ii = 0\n",
    "\n",
    "bb = get_bounding_box(img_files[ii])\n",
    "im = PIL.Image.open(img_files[ii])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "for each in bb:\n",
    "    each = each.cpu()\n",
    "    height = each[1] - each[3]\n",
    "    width = each[2] - each[0]\n",
    "    rect = patches.Rectangle((each[0], each[1] - height), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06374f03",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "topside = DataBlock(\n",
    "    blocks = (ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "    n_inp=1,\n",
    "    get_items = get_image_files,\n",
    "    get_y = get_y,\n",
    "    splitter = FuncSplitter(lambda s: Path(s).parent.name == 'val'),\n",
    "    batch_tfms=[*aug_transforms(size=(240,320)),\n",
    "                Normalize.from_stats(*imagenet_stats)]\n",
    ")\n",
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f31f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "topside.summary(path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = topside.dataloaders(path, device=def_device)\n",
    "print(default_device())\n",
    "dls.show_batch(max_n=3, figsize=(15, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca0f39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "dls = topside.dataloaders(path, bs=16)\n",
    "xb,yb,lb = dls.one_batch()\n",
    "print(xb.shape,yb.shape,lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = detr_learner(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b368f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wwf.vision.object_detection import *\n",
    "\n",
    "encoder = create_body(resnet18(), pretrained=True) #, pretrained=True)\n",
    "encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9d987",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "get_c(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab607e54",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "arch = RetinaNet(encoder, get_c(dls), final_bias=-4)\n",
    "arch.to(device)\n",
    "arch.smoothers, arch.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0944f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [1/2,1,2]\n",
    "scales = [1,2**(-1/3), 2**(-2/3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47347d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "crit = RetinaNetFocalLoss(scales=scales, ratios=ratios)\n",
    "crit.to(device)\n",
    "def _retinanet_split(m): return L(m.encoder,nn.Sequential(m.c5top6, m.p6top7, m.merges, m.smoothers, m.classifier, m.box_regressor)).map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a390f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, arch, loss_func=crit)#, splitter=_retinanet_split)\n",
    "learn.to(device)\n",
    "print(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1cd39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197b80b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c970c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, slice(1e-5, 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.device = 'mps:0'\n",
    "print(torch.backends.mps.is_built())\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
